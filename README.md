# Whispered Diffusion

**Speech â†’ Text â†’ Image**  
A fully local voice-to-image AI pipeline using **Faster-Whisper** and **Stable Diffusion**.  
Runs on your machine, **no APIs, no cloud, no accounts**.

Built as a practical end-to-end AI systems project and portfolio demo.

---

## What It Does

1. Records a spoken prompt ('push-to-talk' via microphone)  
2. Transcribes speech using **Faster-Whisper**  
3. Converts transcript into an image prompt  
4. Generates an image using **Stable Diffusion Turbo**  
5. Saves the final output locally  

Everything runs **locally on CPU by default**.

---

## Quick Start (Bare Metal, No Docker)

### 1. Clone the project
```bash
git clone https://github.com/spetersCompute/whisperedDiffusion.git
cd whisperedDiffusion
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
pip install torch==2.3.0
```

### 3. Run the app
```bash
python -m src.app
```

### Controls
- Press `r` to start recording  
- Speak your prompt  
- Press `s` to stop recording  
- Image is generated automatically into `data/output/`

---

## Project Structure

```
whisperedDiffusion/
â”œâ”€ src/
â”‚  â”œâ”€ app.py            # Entry point / orchestration
â”‚  â”œâ”€ capture.py        # Microphone + audio capture
â”‚  â”œâ”€ pipeline.py       # Transcript â†’ prompt â†’ image
â”‚  â”œâ”€ whisper_client.py
â”‚  â”œâ”€ diffusion_client.py
â”‚
â”œâ”€ data/
â”‚  â”œâ”€ input/            # Temporary audio files
â”‚  â”œâ”€ output/           # Generated images
â”‚  â””â”€ cache/            # HuggingFace cache
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## Tech Used

- Python  
- Faster-Whisper (speech â†’ text)  
- Stable Diffusion Turbo (text â†’ image)  
- sounddevice (audio capture)  
- threading + callbacks  
- HuggingFace models (local inference)

---

## Why This Exists

This project demonstrates:

âœ” Building a real end-to-end AI pipeline  
âœ” Audio capture, threading, and real IO  
âœ” Modular architecture (capture â†’ app â†’ pipeline)  
âœ” Running AI systems locally instead of via cloud APIs   

---

## Roadmap

- Direct NumPy audio â†’ Whisper (no temp WAV)  
- Streaming transcription mode  
- GPU acceleration (CUDA, OpenVINO, Intel Arc)  
- Containerized deployment (ðŸ’€) 
- More advanced diffusion models (SDXL, Flux)

---

## License

MIT
